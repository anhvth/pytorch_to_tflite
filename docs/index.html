---

title: Install


keywords: fastai
sidebar: home_sidebar



nb_path: "nbs/index.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: nbs/index.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><code>pip install pytorch_to_tflite</code></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="How-to-use">How to use<a class="anchor-link" href="#How-to-use"> </a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Pytorch-to-Onnx">Pytorch to Onnx<a class="anchor-link" href="#Pytorch-to-Onnx"> </a></h2>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span> 
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">pytorch_to_tflite.pytorch_to_tflite</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">yaml</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">mmcv</span>
<span class="kn">from</span> <span class="nn">nanodet.model.arch</span> <span class="kn">import</span> <span class="n">build_model</span>

<span class="n">PATH_TO_CONFIG</span> <span class="o">=</span> <span class="s1">&#39;/gitprojects/nano-det-parkingline/config/nanodet-g.yml&#39;</span>
<span class="n">cfg</span> <span class="o">=</span> <span class="n">yaml</span><span class="o">.</span><span class="n">safe_load</span><span class="p">(</span><span class="nb">open</span><span class="p">(</span><span class="n">PATH_TO_CONFIG</span><span class="p">))</span>
<span class="n">cfg</span> <span class="o">=</span> <span class="n">mmcv</span><span class="o">.</span><span class="n">Config</span><span class="p">(</span><span class="n">cfg</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">build_model</span><span class="p">(</span><span class="n">cfg</span><span class="o">.</span><span class="n">model</span><span class="p">)</span>

<span class="n">img</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">416</span><span class="p">,</span><span class="mi">416</span><span class="p">)</span>
<span class="n">out</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>

<span class="o">!</span>mkdir -p cache/
<span class="n">onnx_out_path</span> <span class="o">=</span> <span class="s1">&#39;cache/out.onnx&#39;</span>
<span class="n">torch</span><span class="o">.</span><span class="n">onnx</span><span class="o">.</span><span class="n">export</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">img</span><span class="p">,</span> <span class="n">onnx_out_path</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Finish initialize Lite GFL Head.
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>/root/miniconda3/envs/pytorch-to-tflite/lib/python3.9/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)
  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
/root/miniconda3/envs/pytorch-to-tflite/lib/python3.9/site-packages/torch/nn/functional.py:3609: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  warnings.warn(
/root/miniconda3/envs/pytorch-to-tflite/lib/python3.9/site-packages/torch/nn/functional.py:3657: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. 
  warnings.warn(
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="ONNX-to-Tensorflow">ONNX to Tensorflow<a class="anchor-link" href="#ONNX-to-Tensorflow"> </a></h1>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">onnx_path</span> <span class="o">=</span> <span class="n">onnx_out_path</span>
<span class="n">tf_path</span> <span class="o">=</span> <span class="n">onnx_path</span> <span class="o">+</span> <span class="s1">&#39;.tf&#39;</span>
<span class="n">onnx_to_tf</span><span class="p">(</span><span class="n">onnx_path</span><span class="o">=</span><span class="n">onnx_path</span><span class="p">,</span> <span class="n">tf_path</span><span class="o">=</span><span class="n">tf_path</span><span class="p">)</span>
<span class="k">assert</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">tf_path</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Tensorflow-to-tflite">Tensorflow to tflite<a class="anchor-link" href="#Tensorflow-to-tflite"> </a></h1>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tflite_path</span> <span class="o">=</span> <span class="n">tf_path</span><span class="o">+</span><span class="s1">&#39;.tflite&#39;</span>
<span class="n">tf_to_tf_lite</span><span class="p">(</span><span class="n">tf_path</span><span class="p">,</span> <span class="n">tflite_path</span><span class="p">)</span>
<span class="k">assert</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">tflite_path</span><span class="p">)</span>
<span class="n">tflite_path</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

</div>
 

