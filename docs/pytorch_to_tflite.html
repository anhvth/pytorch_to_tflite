---

title: PytorchToTflite

keywords: fastai
sidebar: home_sidebar

summary: "API details."
description: "API details."
nb_path: "00_pytorch_to_tflite.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: 00_pytorch_to_tflite.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%</span><span class="k">load_ext</span> autoreload
<span class="o">%</span><span class="k">autoreload</span> 2
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>The autoreload extension is already loaded. To reload it, use:
  %reload_ext autoreload
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="get_example_input" class="doc_header"><code>get_example_input</code><a href="__main__.py#L20" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>get_example_input</code>(<strong><code>size</code></strong>)</p>
</blockquote>
<p>Loads image from disk and converts to compatible shape.
:param image_file: Path to single image file
:return: Original image, numpy.ndarray instance image, torch.Tensor image</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="torch_to_onnx" class="doc_header"><code>torch_to_onnx</code><a href="__main__.py#L42" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>torch_to_onnx</code>(<strong><code>torch_path</code></strong>, <strong><code>onnx_path</code></strong>, <strong><code>image_path</code></strong>)</p>
</blockquote>
<p>Converts PyTorch model file to ONNX with usable op-set
:param torch_path: Torch model path to load
:param onnx_path: ONNX model path to save
:param image_path: Path of test image to use in export progress</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="onnx_to_tf" class="doc_header"><code>onnx_to_tf</code><a href="__main__.py#L64" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>onnx_to_tf</code>(<strong><code>onnx_path</code></strong>, <strong><code>tf_path</code></strong>)</p>
</blockquote>
<p>Converts ONNX model to TF 2.X saved file
:param onnx_path: ONNX model path to load
:param tf_path: TF path to save</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="tf_to_tf_lite" class="doc_header"><code>tf_to_tf_lite</code><a href="__main__.py#L77" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>tf_to_tf_lite</code>(<strong><code>tf_path</code></strong>, <strong><code>tf_lite_path</code></strong>)</p>
</blockquote>
<p>Converts TF saved model into TFLite model
:param tf_path: TF saved model path to load
:param tf_lite_path: TFLite model path to save</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="get_torch_model" class="doc_header"><code>get_torch_model</code><a href="__main__.py#L90" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>get_torch_model</code>(<strong><code>model_path</code></strong>)</p>
</blockquote>
<p>Loads state-dict into model and creates an instance
:param model_path: State-dict path to load PyTorch model with pre-trained weights
:return: PyTorch model instance</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="get_tf_lite_model" class="doc_header"><code>get_tf_lite_model</code><a href="__main__.py#L100" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>get_tf_lite_model</code>(<strong><code>model_path</code></strong>)</p>
</blockquote>
<p>Creates an instance of TFLite CPU interpreter
:param model_path: TFLite model path to initialize
:return: TFLite interpreter</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="predict_torch" class="doc_header"><code>predict_torch</code><a href="__main__.py#L112" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>predict_torch</code>(<strong><code>model</code></strong>, <strong><code>image</code></strong>)</p>
</blockquote>
<p>Torch model prediction (forward propagate)
:param model: PyTorch model
:param image: Input image
:return: Numpy array with logits</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="predict_tf_lite" class="doc_header"><code>predict_tf_lite</code><a href="__main__.py#L173" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>predict_tf_lite</code>(<strong><code>model</code></strong>, <strong><code>image</code></strong>)</p>
</blockquote>
<p>TFLite model prediction (forward propagate)
:param model: TFLite interpreter
:param image: Input image
:return: Numpy array with logits</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="calc_error" class="doc_header"><code>calc_error</code><a href="__main__.py#L137" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>calc_error</code>(<strong><code>res1</code></strong>, <strong><code>res2</code></strong>, <strong><code>verbose</code></strong>=<em><code>False</code></em>)</p>
</blockquote>
<p>Calculates specified error between two results. In here Mean-Square-Error and Mean-Absolute-Error calculated"
:param res1: First result
:param res2: Second result
:param verbose: Print loss results
:return: Loss metrics as a dictionary</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="predict_onnx" class="doc_header"><code>predict_onnx</code><a href="__main__.py#L155" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>predict_onnx</code>(<strong><code>onnx_path</code></strong>, <strong><code>sample</code></strong>)</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="onnx_to_keras" class="doc_header"><code>onnx_to_keras</code><a href="__main__.py#L161" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>onnx_to_keras</code>(<strong><code>onnx_path</code></strong>, <strong><code>tf_path</code></strong>)</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="predict_tf_lite" class="doc_header"><code>predict_tf_lite</code><a href="__main__.py#L173" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>predict_tf_lite</code>(<strong><code>model</code></strong>, <strong><code>image</code></strong>)</p>
</blockquote>
<p>TFLite model prediction (forward propagate)
:param model: TFLite interpreter
:param image: Input image
:return: Numpy array with logits</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Pytorch-to-Onnx">Pytorch to Onnx<a class="anchor-link" href="#Pytorch-to-Onnx"> </a></h1>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">cat</span> <span class="o">../</span><span class="n">nano</span><span class="o">-</span><span class="n">det</span><span class="o">-</span><span class="n">parkingline</span><span class="o">/</span><span class="n">config</span><span class="o">/</span><span class="n">nanodet</span><span class="o">-</span><span class="n">g</span><span class="o">.</span><span class="n">yml</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre># NanoDet-g-416 is designed for edge NPU, GPU or TPU with high parallel computing power but low memory bandwidth
# COCO mAP(0.5:0.95) = 22.9
# Flops = 4.2B
# Params = 3.8M
# COCO pre-trained weight link: https://drive.google.com/file/d/10uW7oqZKw231l_tr4C1bJWkbCXgBf7av/view?usp=sharing
save_dir: workspace/nanodet_g
model:
  arch:
    name: OneStageDetector
    backbone:
      name: CustomCspNet
      net_cfg: [[ &#39;Conv&#39;, 3, 32, 3, 2],  # 1/2
                [ &#39;MaxPool&#39;, 3, 2 ],  # 1/4
                [ &#39;CspBlock&#39;, 32, 1, 3, 1 ],  # 1/4
                [ &#39;CspBlock&#39;, 64, 2, 3, 2 ],  # 1/8
                [ &#39;CspBlock&#39;, 128, 2, 3, 2 ],  # 1/16
                [ &#39;CspBlock&#39;, 256, 3, 3, 2 ]]  # 1/32
      out_stages: [3,4,5]
      activation: LeakyReLU
    fpn:
      name: PAN
      in_channels: [128, 256, 512]
      out_channels: 128
      start_level: 0
      num_outs: 3
    head:
      name: NanoDetHead
      num_classes: 80
      conv_type: Conv
      activation: LeakyReLU
      input_channel: 128
      feat_channels: 128
      stacked_convs: 1
      share_cls_reg: True
      octave_base_scale: 8
      scales_per_octave: 1
      strides: [8, 16, 32]
      reg_max: 10
      norm_cfg:
        type: BN
      loss:
        loss_qfl:
          name: QualityFocalLoss
          use_sigmoid: True
          beta: 2.0
          loss_weight: 1.0
        loss_dfl:
          name: DistributionFocalLoss
          loss_weight: 0.25
        loss_bbox:
          name: GIoULoss
          loss_weight: 2.0
data:
  train:
    name: coco
    img_path: coco/train2017
    ann_path: coco/annotations/instances_train2017.json
    input_size: [416,416] #[w,h]
    keep_ratio: True
    pipeline:
      perspective: 0.0
      scale: [0.6, 1.4]
      stretch: [[1, 1], [1, 1]]
      rotation: 0
      shear: 0
      translate: 0.2
      flip: 0.5
      brightness: 0.2
      contrast: [0.6, 1.4]
      saturation: [0.5, 1.2]
      normalize: [[103.53, 116.28, 123.675], [57.375, 57.12, 58.395]]
  val:
    name: coco
    img_path: coco/val2017
    ann_path: coco/annotations/instances_val2017.json
    input_size: [416,416] #[w,h]
    keep_ratio: True
    pipeline:
      normalize: [[103.53, 116.28, 123.675], [57.375, 57.12, 58.395]]
device:
  gpu_ids: [0]
  workers_per_gpu: 10
  batchsize_per_gpu: 128
schedule:
#  resume:
#  load_model: YOUR_MODEL_PATH
  optimizer:
    name: SGD
    lr: 0.1
    momentum: 0.9
    weight_decay: 0.0001
  warmup:
    name: linear
    steps: 500
    ratio: 0.01
  total_epochs: 190
  lr_schedule:
    name: MultiStepLR
    milestones: [130,160,175,185]
    gamma: 0.1
  val_intervals: 5
evaluator:
  name: CocoDetectionEvaluator
  save_key: mAP

log:
  interval: 10

class_names: [&#39;person&#39;, &#39;bicycle&#39;, &#39;car&#39;, &#39;motorcycle&#39;, &#39;airplane&#39;, &#39;bus&#39;,
              &#39;train&#39;, &#39;truck&#39;, &#39;boat&#39;, &#39;traffic_light&#39;, &#39;fire_hydrant&#39;,
              &#39;stop_sign&#39;, &#39;parking_meter&#39;, &#39;bench&#39;, &#39;bird&#39;, &#39;cat&#39;, &#39;dog&#39;,
              &#39;horse&#39;, &#39;sheep&#39;, &#39;cow&#39;, &#39;elephant&#39;, &#39;bear&#39;, &#39;zebra&#39;, &#39;giraffe&#39;,
              &#39;backpack&#39;, &#39;umbrella&#39;, &#39;handbag&#39;, &#39;tie&#39;, &#39;suitcase&#39;, &#39;frisbee&#39;,
              &#39;skis&#39;, &#39;snowboard&#39;, &#39;sports_ball&#39;, &#39;kite&#39;, &#39;baseball_bat&#39;,
              &#39;baseball_glove&#39;, &#39;skateboard&#39;, &#39;surfboard&#39;, &#39;tennis_racket&#39;,
              &#39;bottle&#39;, &#39;wine_glass&#39;, &#39;cup&#39;, &#39;fork&#39;, &#39;knife&#39;, &#39;spoon&#39;, &#39;bowl&#39;,
              &#39;banana&#39;, &#39;apple&#39;, &#39;sandwich&#39;, &#39;orange&#39;, &#39;broccoli&#39;, &#39;carrot&#39;,
              &#39;hot_dog&#39;, &#39;pizza&#39;, &#39;donut&#39;, &#39;cake&#39;, &#39;chair&#39;, &#39;couch&#39;,
              &#39;potted_plant&#39;, &#39;bed&#39;, &#39;dining_table&#39;, &#39;toilet&#39;, &#39;tv&#39;, &#39;laptop&#39;,
              &#39;mouse&#39;, &#39;remote&#39;, &#39;keyboard&#39;, &#39;cell_phone&#39;, &#39;microwave&#39;,
              &#39;oven&#39;, &#39;toaster&#39;, &#39;sink&#39;, &#39;refrigerator&#39;, &#39;book&#39;, &#39;clock&#39;,
              &#39;vase&#39;, &#39;scissors&#39;, &#39;teddy_bear&#39;, &#39;hair_drier&#39;, &#39;toothbrush&#39;]
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">yaml</span>
<span class="kn">import</span> <span class="nn">mmcv</span>
<span class="kn">from</span> <span class="nn">nanodet.model.arch</span> <span class="kn">import</span> <span class="n">build_model</span>

<span class="n">PATH_TO_CONFIG</span> <span class="o">=</span> <span class="s1">&#39;../nano-det-parkingline/config/nanodet-g.yml&#39;</span>
<span class="n">cfg</span> <span class="o">=</span> <span class="n">yaml</span><span class="o">.</span><span class="n">safe_load</span><span class="p">(</span><span class="nb">open</span><span class="p">(</span><span class="n">PATH_TO_CONFIG</span><span class="p">))</span>
<span class="n">cfg</span> <span class="o">=</span> <span class="n">mmcv</span><span class="o">.</span><span class="n">Config</span><span class="p">(</span><span class="n">cfg</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">build_model</span><span class="p">(</span><span class="n">cfg</span><span class="o">.</span><span class="n">model</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Finish initialize Lite GFL Head.
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">img</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">416</span><span class="p">,</span><span class="mi">416</span><span class="p">)</span>
<span class="n">out</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>/root/miniconda3/envs/pytorch-to-tflite/lib/python3.9/site-packages/torch/nn/functional.py:3609: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  warnings.warn(
/root/miniconda3/envs/pytorch-to-tflite/lib/python3.9/site-packages/torch/nn/functional.py:3657: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. 
  warnings.warn(
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span>mkdir -p cache/
<span class="n">onnx_out_path</span> <span class="o">=</span> <span class="s1">&#39;cache/out.onnx&#39;</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">onnx</span><span class="o">.</span><span class="n">export</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">img</span><span class="p">,</span> <span class="n">onnx_out_path</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>/root/miniconda3/envs/pytorch-to-tflite/lib/python3.9/site-packages/torch/onnx/symbolic_helper.py:374: UserWarning: You are trying to export the model with onnx:Upsample for ONNX opset version 9. This operator might cause results to not match the expected results by PyTorch.
ONNX&#39;s Upsample/Resize operator did not match Pytorch&#39;s Interpolation until opset 11. Attributes to determine how to transform the input were added in onnx:Resize in opset 11 to support Pytorch&#39;s behavior (like coordinate_transformation_mode and nearest_mode).
We recommend using opset 11 and above for models using this operator. 
  warnings.warn(&#34;You are trying to export the model with &#34; + onnx_op + &#34; for ONNX opset version &#34;
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="ONNX-to-Tensorflow">ONNX to Tensorflow<a class="anchor-link" href="#ONNX-to-Tensorflow"> </a></h1>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">onnx_path</span> <span class="o">=</span> <span class="n">onnx_out_path</span>
<span class="n">tf_path</span> <span class="o">=</span> <span class="n">onnx_path</span> <span class="o">+</span> <span class="s1">&#39;.tf&#39;</span>
<span class="n">onnx_to_tf</span><span class="p">(</span><span class="n">onnx_path</span><span class="o">=</span><span class="n">onnx_path</span><span class="p">,</span> <span class="n">tf_path</span><span class="o">=</span><span class="n">tf_path</span><span class="p">)</span>
<span class="k">assert</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">tf_path</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>WARNING:absl:Function `__call__` contains input name(s) input.1 with unsupported characters which will be renamed to input_1 in the SavedModel.
WARNING:absl:Found untraced functions such as gen_tensor_dict while saving (showing 1 of 1). These functions will not be directly callable after loading.
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>INFO:tensorflow:Assets written to: cache/out.onnx.tf/assets
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>INFO:tensorflow:Assets written to: cache/out.onnx.tf/assets
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Tensorflow-to-tflite">Tensorflow to tflite<a class="anchor-link" href="#Tensorflow-to-tflite"> </a></h1>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tflite_path</span> <span class="o">=</span> <span class="n">tf_path</span><span class="o">+</span><span class="s1">&#39;.tflite&#39;</span>
<span class="n">tf_to_tf_lite</span><span class="p">(</span><span class="n">tf_path</span><span class="p">,</span> <span class="n">tflite_path</span><span class="p">)</span>
<span class="k">assert</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">tflite_path</span><span class="p">)</span>
<span class="n">tflite_path</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&#39;cache/out.onnx.tf.tflite&#39;</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

</div>
 

